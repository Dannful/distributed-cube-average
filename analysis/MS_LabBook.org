#+TITLE: LabBook to follow Spadotto's Undergraduate Thesis
#+AUTHOR: Lucas M. Schnorr
#+STARTUP: overview indent
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

* Packages

#+begin_src R :results silent :session *R* :exports both :noweb yes :colnames yes
  library(tidyverse)
  library(here)
#+end_src

* Advancements

** 2025, Saturday, 27 September

*Problem*: the hash of the output produced *in parallel* (sequentially works fine) by our application did not match that of the original.

*Partial solution*:
The study object was improperly using the wrong indices for the anisotropy variables: since every worker computes the precomputation and anisotropy
variables on their own (for the sake of having work to do before receiving the assigned portion of the cube from the coordinator), they were wrongly
using their local indices (worker indices) instead of the global ones, which are the ones used by the original application.

** 2025, Monday, 29 September

*Problem*: the hash of the output produced *in parallel* (sequentially works fine) by our application did not match that of the original.
*Final solution*:
The original application utilizes cross derivatives between X and Y, which requires diagonals to be exchanged between halo regions.
This wasn't present in our implementation, so diagonal communications were implemented.

*Problem*: the source insertion was poorly handled, making the output hash differ from the proper one.
*Solution*: make every worker insert the source on their own on *pc* and *qc*, which ensures they have the correct data available to compute with.

** 2025, Tuesday, 30 September

*Problem*: *MPI_cart_rank* was being called every iteration by every worker in order to find their neighbours, which is an unnecessary MPI overhead.
*Solution*: bringing all these calls to the beginning of the application

*Problem*: *MPI_Waitall* was being called twice per iteration with the purpose of waiting the two halo receivings (for *pp* and *qp*), introducing
an unnecessary MPI overhead.
*Solution*: merged both requests into one larger *MPI_Request* array before calling a single *MPI_Waitall*.

* Meetings
** 2025-10-01
*** Convert RST \to CSV

#+begin_src shell :results silent :exports both
aky_converter --no-links 2025-10-01/rastro-*.rst | \
    pj_dump | \
    grep ^State > saida.csv
#+end_src

*** Read

#+begin_src R :results silent :session *R* :exports both :noweb yes :colnames yes
options(crayon.enabled=FALSE)
suppressMessages(library(tidyverse))
read_csv(here::here("analysis/saida.csv"), col_names=FALSE, progress=FALSE, show_col_types=FALSE) |>
  select(rank = X2, start = X4, end = X5, duration = X6, state = X8) |>
  mutate(rank = as.integer(gsub("rank", "", rank))) |>
  mutate(state = as.factor(state)) -> df
#+end_src

*** Define true start and end

#+begin_src R :results silent :session *R* :exports both :noweb yes :colnames yes
df |>
  filter(state == "MPI_Recv") |>
  filter(start == min(start)) |>
  pull(start) -> s.start

df |>
  filter(state == "MPI_Waitall") |>
  filter(end == max(end)) |>
  pull(end) -> s.end
#+end_src

*** Consider only the middle of the execution

#+begin_src R :results silent :session *R* :exports both :noweb yes :colnames yes
  df |>
    filter(!(state %in% c("MPI_Recv", # remove o recv inicial
                        "MPI_Send", # remove o send inicial
                        "MPI_Cart_rank", # remove as chamadas de rank finais
                        "MPI_Wtime"))) |>
    filter(start >= s.start) |>
    filter(end <= s.end) -> df.filtered
#+end_src

*** Consider only when everyone is working

#+begin_src R :results none :session :exports both :noweb yes :colnames yes
df.filtered |>
  group_by(rank) |>
  arrange(start) |>
  slice(1) |>
  ungroup() |>
  arrange(start) |>
  slice(n()) |>
  pull(start) -> s.start

bind_rows(
  df.filtered |>
  filter(start <= s.start & end >= s.start) |>
  mutate(start = s.start)
,
  df.filtered |>
  filter(!(start <= s.start & end >= s.start)) |>
  filter(start >= s.start)
) -> df.filtered2
#+end_src

#+RESULTS:

*** Stats

#+begin_src R :results silent :session *R* :exports both :noweb yes :colnames yes
df.filtered2 |>
  group_by(rank) |>
  summarize(MPI.time = sum(duration),
            Makespan.time = max(end) * length(unique(rank))) |>
  mutate(P = round(MPI.time / Makespan.time * 100, 2)) |>
  write_csv("mpi_time_per_rank.csv", progress=FALSE) |>
  ungroup() |>
  filter(rank != 0) |> # because 0 is a bit different in the beginning and in the end
  summarize(MPI.time = sum(MPI.time),
            Makespan.time = sum(Makespan.time)) |>
  mutate(P = round(MPI.time / Makespan.time * 100, 2)) |>
  write_csv("mpi_time_global.csv")
#+end_src

#+RESULTS:

*** Plot
#+begin_src R :results output :session *R* :exports both :noweb yes :colnames yes
df.filtered2 |>
  ggplot(aes(fill = state, color = state,
             xmin = start, xmax = end,
             ymin = rank-0.3, ymax = rank+0.3)) +
  geom_rect()
ggsave("saida.pdf")
#+end_src

#+RESULTS:
: Saving 6.99 x 7 in image
